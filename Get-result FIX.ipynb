{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchmetrics.text import CharErrorRate\n",
    "\n",
    "import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\".\")\n",
    "DEVICE = \"cuda\"\n",
    "# Data Size\n",
    "DATA_SIZE = 100000\n",
    "# Mask\n",
    "MASK = 0.4\n",
    "# Loader\n",
    "LOADER_WORKER = 0  # Default = 0\n",
    "BATCH_SIZE = 1\n",
    "# NN\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYER = 2  #\n",
    "DROPOUT = 0.4\n",
    "# Train\n",
    "NUM_EPOCHS = 45\n",
    "PATIENCE = 3\n",
    "LABEL_SMOOTH = 0.1\n",
    "# Debug\n",
    "DEBUG = False\n",
    "DEBUG_ONE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(DEVICE)\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_path = PATH.joinpath(\"voc\").absolute()\n",
    "with open(voc_path, \"rb\") as voc_file:\n",
    "    voc = pickle.load(voc_file)\n",
    "WORD_SIZE = len(voc[\"token2idx\"])\n",
    "CHAR_SIZE = len(voc[\"chartoken2idx\"])\n",
    "SEMI_CHAR_VEC_SIZE = CHAR_SIZE * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_train_dataset_path = PATH.joinpath(\"normalization_dataset/\").joinpath(\n",
    "    \"normalization_train.1blm.noise.random\"\n",
    ")\n",
    "label_train_dataset_path = PATH.joinpath(\"normalization_dataset/\").joinpath(\n",
    "    \"normalization_train.1blm\"\n",
    ")\n",
    "noise_test_dataset_path = PATH.joinpath(\"normalization_dataset/\").joinpath(\n",
    "    \"normalization_test.1blm.noise.random\"\n",
    ")\n",
    "label_test_dataset_path = PATH.joinpath(\"normalization_dataset/\").joinpath(\n",
    "    \"normalization_test.1blm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Model.spell_correction_dataset(\n",
    "    noise_dataset_path=noise_test_dataset_path,\n",
    "    ref_dataset_path=label_test_dataset_path,\n",
    "    voc=voc,\n",
    "    transform=Model.sentence_to_semi_char_tensor,\n",
    "    label_transform=Model.sentence_to_word_tensor,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dataset, range(DATA_SIZE)),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=Model.collate_fn,\n",
    "    generator=torch.Generator(device=DEVICE),\n",
    "    num_workers=LOADER_WORKER,\n",
    ")\n",
    "sentence_to_semi_char_tensor = partial(Model.sentence_to_semi_char_tensor, mask=MASK)\n",
    "mask_test_dataset = Model.spell_correction_dataset(\n",
    "    noise_dataset_path=label_train_dataset_path,  # no noise\n",
    "    ref_dataset_path=label_train_dataset_path,\n",
    "    voc=voc,\n",
    "    transform=sentence_to_semi_char_tensor,  # mask\n",
    "    label_transform=Model.sentence_to_word_tensor,\n",
    ")\n",
    "mask_test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(mask_test_dataset, range(DATA_SIZE)),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=Model.collate_fn,\n",
    "    generator=torch.Generator(device=DEVICE),\n",
    "    num_workers=LOADER_WORKER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclstm = Model.sclstm(\n",
    "    word_size=WORD_SIZE,\n",
    "    semi_char_vec_size=SEMI_CHAR_VEC_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYER,\n",
    "    dropout=DROPOUT,\n",
    ")\n",
    "mask_sclstm = Model.sclstm(\n",
    "    word_size=WORD_SIZE,\n",
    "    semi_char_vec_size=SEMI_CHAR_VEC_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYER,\n",
    "    dropout=DROPOUT,\n",
    ")\n",
    "dp_sclstm = Model.dp_sclstm(\n",
    "    word_size=WORD_SIZE,\n",
    "    semi_char_vec_size=SEMI_CHAR_VEC_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYER,\n",
    "    dropout=DROPOUT,\n",
    ")\n",
    "dp_mask_sclstm = Model.dp_sclstm(\n",
    "    word_size=WORD_SIZE,\n",
    "    semi_char_vec_size=SEMI_CHAR_VEC_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYER,\n",
    "    dropout=DROPOUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH.joinpath(\"model\").joinpath(\"sclstm.pth\").absolute()\n",
    "dp_model_path = PATH.joinpath(\"model\").joinpath(\"dp-sclstm.pth\").absolute()\n",
    "mask_model_path = PATH.joinpath(\"model\").joinpath(\"mask-sclstm.pth\").absolute()\n",
    "dp_mask_model_path = PATH.joinpath(\"model\").joinpath(\"dp-mask-sclstm.pth\").absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclstm.load_state_dict(Model.load_compiled_model(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_sclstm.load_state_dict(Model.load_dp_model(dp_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_sclstm.load_state_dict(Model.load_compiled_model(mask_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_mask_sclstm.load_state_dict(Model.load_dp_model(dp_mask_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_text(model, data_loader, voc_fn):\n",
    "    model.eval()\n",
    "    text_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(data_loader):\n",
    "            y_logit_pred = model(x_batch)\n",
    "            y_logit_pred = y_logit_pred[0]\n",
    "            text_pred = Model.word_tensor_to_sentence(y_logit_pred, voc_fn)\n",
    "            text_preds.append(text_pred)\n",
    "\n",
    "            if DEBUG:\n",
    "                print(text_pred)\n",
    "\n",
    "            if DEBUG_ONE:\n",
    "                break\n",
    "\n",
    "    return text_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(list_string, path):\n",
    "    file = open(path, \"w\")\n",
    "    for string in list_string:\n",
    "        file.write(string)\n",
    "        file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_predict_text(model=sclstm, data_loader=test_loader, voc_fn=voc)\n",
    "pred_path = PATH.joinpath(\"result\").joinpath(\"prediction\").absolute()\n",
    "write_to_file(preds, pred_path)\n",
    "del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_preds = get_predict_text(model=dp_sclstm, data_loader=test_loader, voc_fn=voc)\n",
    "dp_pred_path = PATH.joinpath(\"result\").joinpath(\"dp-prediction\").absolute()\n",
    "write_to_file(dp_preds, dp_pred_path)\n",
    "del dp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_preds = get_predict_text(\n",
    "    model=mask_sclstm, data_loader=mask_test_loader, voc_fn=voc\n",
    ")\n",
    "mask_pred_path = PATH.joinpath(\"result\").joinpath(\"mask-prediction\").absolute()\n",
    "write_to_file(mask_preds, mask_pred_path)\n",
    "del mask_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [2:24:30<00:00, 11.53it/s] \n"
     ]
    }
   ],
   "source": [
    "dp_mask_preds = get_predict_text(\n",
    "    model=dp_mask_sclstm, data_loader=mask_test_loader, voc_fn=voc\n",
    ")\n",
    "dp_mask_pred_path = PATH.joinpath(\"result\").joinpath(\"dp-mask-prediction\").absolute()\n",
    "write_to_file(dp_mask_preds, dp_mask_pred_path)\n",
    "del dp_mask_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "non-package-mode--PK69jeh-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
